{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy comunication compression scheme in FedLab\n",
    "\n",
    "This tutorial provides comprehensive examples about implementing a communication efficiency scheme in FedLab. \n",
    "\n",
    "We take the baseline gradient compression algorithms as examples (top-k for gradient sparsification and QSGD for gradient quantization)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/zed/Desktop/Data/FedLab/tutorials/communication_tutorial.ipynb 单元格 3\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zed/Desktop/Data/FedLab/tutorials/communication_tutorial.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zed/Desktop/Data/FedLab/tutorials/communication_tutorial.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39m../\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zed/Desktop/Data/FedLab/tutorials/communication_tutorial.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfedlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontrib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompressor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantization\u001b[39;00m \u001b[39mimport\u001b[39;00m QSGDCompressor\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zed/Desktop/Data/FedLab/tutorials/communication_tutorial.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfedlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontrib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompressor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtopk\u001b[39;00m \u001b[39mimport\u001b[39;00m TopkCompressor\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zed/Desktop/Data/FedLab/tutorials/communication_tutorial.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Data/FedLab/tutorials/../fedlab/contrib/compressor/__init__.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2021 Peng Cheng Laboratory (http://www.szpclab.com/) and FedLab Authors (smilelab.group)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mquantization\u001b[39;00m \u001b[39mimport\u001b[39;00m QSGDCompressor\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtopk\u001b[39;00m \u001b[39mimport\u001b[39;00m TopkCompressor\n",
      "File \u001b[0;32m~/Desktop/Data/FedLab/tutorials/../fedlab/contrib/compressor/quantization.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2021 Peng Cheng Laboratory (http://www.szpclab.com/) and FedLab Authors (smilelab.group)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcompressor\u001b[39;00m \u001b[39mimport\u001b[39;00m Compressor\n\u001b[1;32m     19\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mQSGDCompressor\u001b[39;00m(Compressor):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from fedlab.contrib.compressor.quantization import QSGDCompressor\n",
    "from fedlab.contrib.compressor.topk import TopkCompressor\n",
    "import torch\n",
    "\n",
    "tpk_compressor = TopkCompressor(compress_ratio=0.05) # top 5% gradient\n",
    "qsgd_compressor = QSGDCompressor(n_bit=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be compressed tensor: tensor([ 7.7551e-01, -2.5789e+00, -1.2139e+00,  6.6635e-01,  1.8937e-01,\n",
      "         1.0737e-03,  5.1149e-01,  3.0985e-01,  1.5327e-01, -1.3022e+00,\n",
      "         3.6320e-01, -8.1719e-01, -1.7236e-01,  3.6765e-01,  8.8025e-01,\n",
      "         5.8854e-01,  9.2844e-01,  4.0012e-02, -9.9287e-01,  6.1850e-02,\n",
      "         2.7857e+00,  1.2063e+00,  1.2431e+00,  1.4535e-01, -8.4183e-01,\n",
      "        -3.4871e-02, -3.2011e-02, -6.3319e-01, -3.2209e-01,  2.2956e+00,\n",
      "         2.6015e-01, -1.9257e+00, -6.8645e-01,  1.2412e+00,  2.6703e-02,\n",
      "        -1.6042e+00, -3.5102e-01, -1.4851e+00, -1.5193e+00, -5.9978e-01,\n",
      "        -1.4323e+00,  2.0093e-01,  4.9522e-01,  1.0142e+00, -1.3590e+00,\n",
      "        -1.1961e+00,  8.6942e-01, -3.2653e-02, -1.0595e+00, -1.1150e+00,\n",
      "         6.6425e-01,  2.9663e-01,  8.4232e-01,  1.1350e-02,  1.0860e+00,\n",
      "         6.4058e-01, -1.8474e+00, -9.2868e-02,  2.0592e+00,  1.1361e+00,\n",
      "        -9.5078e-03,  1.2869e-01,  3.9442e-01, -6.9267e-01, -6.6260e-01,\n",
      "        -5.5249e-01, -5.0148e-01,  5.8946e-01,  1.0813e+00, -9.1883e-01,\n",
      "        -4.6265e-01,  7.1538e-01, -7.4536e-01,  9.2024e-01,  2.3843e-01,\n",
      "         1.2144e+00, -9.7016e-03,  7.2887e-01, -7.6980e-02, -1.2985e-01,\n",
      "         2.6185e-01, -1.7867e-01,  3.0731e+00, -1.2736e+00,  1.3126e-01,\n",
      "        -2.8550e-01, -8.7328e-01, -7.4361e-01, -8.8743e-01, -1.8323e-02,\n",
      "         3.8102e+00,  1.5080e+00,  1.3235e+00, -2.1725e-01,  7.6060e-01,\n",
      "         7.0059e-01, -1.2960e-01, -1.5910e-01,  1.3424e+00,  4.3132e-01])\n",
      "Compressed results top-k values: tensor([ 3.8102,  3.0731,  2.7857, -2.5789,  2.2956])\n",
      "Compressed results top-k indices: tensor([90, 82, 20,  1, 29])\n",
      "Decompressed results: tensor([ 0.0000, -2.5789,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  2.7857,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.2956,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  3.0731,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  3.8102,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "# top-k\n",
    "tensor = torch.randn(size=(100,))\n",
    "shape = tensor.shape\n",
    "print(\"To be compressed tensor:\", tensor)\n",
    "\n",
    "# compress\n",
    "values, indices = tpk_compressor.compress(tensor)\n",
    "print(\"Compressed results top-k values:\",values)\n",
    "print(\"Compressed results top-k indices:\", indices)\n",
    "\n",
    "# decompress\n",
    "decompressed = tpk_compressor.decompress(values, indices, shape)\n",
    "print(\"Decompressed results:\", decompressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be compressed tensor: tensor([ 0.6994, -1.1251, -0.9299, -0.6352,  0.2741,  1.5824,  0.0894,  1.5732,\n",
      "         0.7831, -0.0198,  0.2224, -0.4793, -0.2897,  1.6225,  0.7523, -1.7849,\n",
      "         0.4316, -0.1608, -0.6759,  1.0389,  0.1073,  1.1752,  0.1218, -0.3599,\n",
      "        -1.3481, -0.4494, -0.5059,  1.2226,  0.7338, -0.2230,  0.6289,  0.5322,\n",
      "        -0.1944,  0.7647,  0.5396,  0.5470, -0.1616,  1.4421, -0.2432,  1.8598,\n",
      "        -1.2581, -0.7223, -0.5471,  1.6624,  0.7318, -0.0626,  1.6238, -0.8099,\n",
      "        -0.1461,  0.4893,  0.9783, -0.0033, -1.4855, -0.2551,  0.1569, -0.3270,\n",
      "         0.0954,  1.3373, -1.3616, -0.6106, -0.3886,  0.0768,  0.0695, -1.7971,\n",
      "        -1.2371,  0.7987,  0.8369,  1.0450, -0.6797, -0.2286,  1.4056, -1.3860,\n",
      "         0.2538,  0.3095, -1.7382,  1.2275,  0.4352,  0.1406, -0.8640,  0.1920,\n",
      "         1.4031,  0.2131, -0.0194, -1.2062,  0.8262, -0.3393,  2.3612,  1.2369,\n",
      "         0.4217, -0.7969,  0.2939, -0.8274, -1.1822,  0.0056, -1.5248,  0.9979,\n",
      "         0.7542, -0.5605,  0.9131,  0.4680])\n",
      "Compressed results QSGD norm: tensor([2.3612])\n",
      "Compressed results QSGD signs: tensor([ True, False, False, False,  True,  True,  True,  True,  True, False,\n",
      "         True, False, False,  True,  True, False,  True, False, False,  True,\n",
      "         True,  True,  True, False, False, False, False,  True,  True, False,\n",
      "         True,  True, False,  True,  True,  True, False,  True, False,  True,\n",
      "        False, False, False,  True,  True, False,  True, False, False,  True,\n",
      "         True, False, False, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False, False,  True,  True,  True, False, False,\n",
      "         True, False,  True,  True, False,  True,  True,  True, False,  True,\n",
      "         True,  True, False, False,  True, False,  True,  True,  True, False,\n",
      "         True, False, False,  True, False,  True,  True, False,  True,  True])\n",
      "Compressed results QSGD values: tensor([ 76, 122, 101,  69,  30, 172,  10, 171,  85,   3,  24,  52,  31, 176,\n",
      "         82, 193,  47,  18,  73, 113,  12, 128,  14,  39, 146,  49,  55, 133,\n",
      "         80,  25,  68,  58,  21,  82,  58,  59,  17, 156,  26, 201, 137,  79,\n",
      "         59, 180,  80,   6, 176,  87,  16,  53, 106,   1, 161,  27,  17,  35,\n",
      "         10, 145, 147,  66,  43,   9,   7, 195, 134,  87,  91, 113,  73,  25,\n",
      "        153, 151,  28,  34, 189, 133,  47,  16,  93,  21, 152,  23,   2, 131,\n",
      "         90,  37, 256, 134,  46,  86,  31,  90, 128,   0, 166, 108,  82,  61,\n",
      "         99,  51], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# qsgd\n",
    "tensor = torch.randn(size=(100,))\n",
    "shape = tensor.shape\n",
    "print(\"To be compressed tensor:\", tensor)\n",
    "\n",
    "# compress\n",
    "norm, signs, values = qsgd_compressor.compress(tensor)\n",
    "print(\"Compressed results QSGD norm:\", norm)\n",
    "print(\"Compressed results QSGD signs:\", signs)\n",
    "print(\"Compressed results QSGD values:\", values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decompressed results: tensor([ 0.7010, -1.1253, -0.9316, -0.6364,  0.2767,  1.5864,  0.0922,  1.5772,\n",
      "         0.7840, -0.0277,  0.2214, -0.4796, -0.2859,  1.6233,  0.7563, -1.7801,\n",
      "         0.4335, -0.1660, -0.6733,  1.0423,  0.1107,  1.1806,  0.1291, -0.3597,\n",
      "        -1.3466, -0.4520, -0.5073,  1.2267,  0.7379, -0.2306,  0.6272,  0.5350,\n",
      "        -0.1937,  0.7563,  0.5350,  0.5442, -0.1568,  1.4389, -0.2398,  1.8539,\n",
      "        -1.2636, -0.7287, -0.5442,  1.6602,  0.7379, -0.0553,  1.6233, -0.8024,\n",
      "        -0.1476,  0.4888,  0.9777, -0.0092, -1.4850, -0.2490,  0.1568, -0.3228,\n",
      "         0.0922,  1.3374, -1.3559, -0.6088, -0.3966,  0.0830,  0.0646, -1.7986,\n",
      "        -1.2359,  0.8024,  0.8393,  1.0423, -0.6733, -0.2306,  1.4112, -1.3927,\n",
      "         0.2583,  0.3136, -1.7432,  1.2267,  0.4335,  0.1476, -0.8578,  0.1937,\n",
      "         1.4020,  0.2121, -0.0184, -1.2083,  0.8301, -0.3413,  2.3612,  1.2359,\n",
      "         0.4243, -0.7932,  0.2859, -0.8301, -1.1806,  0.0000, -1.5311,  0.9961,\n",
      "         0.7563, -0.5626,  0.9131,  0.4704])\n"
     ]
    }
   ],
   "source": [
    "# decompress\n",
    "decompressed = qsgd_compressor.decompress([norm, signs, values])\n",
    "print(\"Decompressed results:\", decompressed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use compressor in federated learning\n",
    "\n",
    "For example on the client side, we could compress the tensors are to compressed and upload the compressed results to server. And server could decompress the tensors follows the compression agreements.\n",
    "\n",
    "In jupyter notebook, we take the standalone scenario as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedlab.contrib.algorithm.basic_client import SGDSerialClientTrainer, SGDClientTrainer\n",
    "from fedlab.contrib.algorithm.basic_server import SyncServerHandler\n",
    "\n",
    "class CompressSerialClientTrainer(SGDSerialClientTrainer):\n",
    "    def setup_compressor(self, compressor):\n",
    "        #self.compressor = TopkCompressor(compress_ratio=k)\n",
    "        self.compressor = compressor\n",
    "\n",
    "    @property\n",
    "    def uplink_package(self):\n",
    "        package = super().uplink_package\n",
    "        new_package = []\n",
    "        for content in package:\n",
    "            pack = [self.compressor.compress(content[0])]\n",
    "            new_package.append(pack)\n",
    "        return new_package\n",
    "\n",
    "class CompressServerHandeler(SyncServerHandler):\n",
    "    def setup_compressor(self, compressor, type):\n",
    "        #self.compressor = TopkCompressor(compress_ratio=k)\n",
    "        self.compressor = compressor\n",
    "        self.type = type\n",
    "\n",
    "    def load(self, payload) -> bool:\n",
    "        if self.type == \"topk\":\n",
    "            values, indices = payload[0]\n",
    "            decompressed_payload = self.compressor.decompress(values, indices, self.model_parameters.shape)\n",
    "\n",
    "        if self.type == \"qsgd\":\n",
    "            n, s, l = payload[0]\n",
    "            decompressed_payload = self.compressor.decompress((n,s,l))\n",
    "        \n",
    "        return super().load([decompressed_payload])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main, this part we follow the pipeline in pipeline_tutorial.ipynb\n",
    "# But replace the hander and trainer by the above defined for communication compression\n",
    "\n",
    "# configuration\n",
    "from opcode import cmp_op\n",
    "from munch import Munch\n",
    "from fedlab.models.mlp import MLP\n",
    "\n",
    "model = MLP(784, 10)\n",
    "args = Munch\n",
    "\n",
    "args.total_client = 100\n",
    "args.alpha = 0.5\n",
    "args.seed = 42\n",
    "args.preprocess = False\n",
    "args.cuda = False\n",
    "args.cmp_op = \"qsgd\" # \"topk, qsgd\"\n",
    "\n",
    "args.k = 0.1 # topk\n",
    "args.bit = 8 # qsgd\n",
    "\n",
    "if args.cmp_op == \"topk\":\n",
    "    compressor = TopkCompressor(args.k)\n",
    "\n",
    "if args.cmp_op == \"qsgd\":\n",
    "    compressor = QSGDCompressor(args.bit)\n",
    "\n",
    "from torchvision import transforms\n",
    "from fedlab.contrib.dataset.partitioned_mnist import PartitionedMNIST\n",
    "\n",
    "fed_mnist = PartitionedMNIST(root=\"../datasets/mnist/\",\n",
    "                             path=\"../datasets/mnist/fedmnist/\",\n",
    "                             num_clients=args.total_client,\n",
    "                             partition=\"noniid-labeldir\",\n",
    "                             dir_alpha=args.alpha,\n",
    "                             seed=args.seed,\n",
    "                             preprocess=args.preprocess,\n",
    "                             download=True,\n",
    "                             verbose=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToPILImage(),\n",
    "                                 transforms.ToTensor()\n",
    "                             ]))\n",
    "\n",
    "dataset = fed_mnist.get_dataset(0)  # get the 0-th client's dataset\n",
    "dataloader = fed_mnist.get_dataloader(\n",
    "    0,\n",
    "    batch_size=128)  # get the 0-th client's dataset loader with batch size 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SyncServerHandler.__init__() got an unexpected keyword argument 'num_clients'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m args\u001b[39m.\u001b[39mcom_round \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m     22\u001b[0m args\u001b[39m.\u001b[39msample_ratio \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m\n\u001b[0;32m---> 24\u001b[0m handler \u001b[39m=\u001b[39m CompressServerHandeler(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     25\u001b[0m                             global_round\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mcom_round,\n\u001b[1;32m     26\u001b[0m                             num_clients\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mtotal_client,\n\u001b[1;32m     27\u001b[0m                             sample_ratio\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49msample_ratio,\n\u001b[1;32m     28\u001b[0m                             cuda\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mcuda)\n\u001b[1;32m     29\u001b[0m handler\u001b[39m.\u001b[39msetup_compressor(compressor, args\u001b[39m.\u001b[39mcmp_op)\n",
      "\u001b[0;31mTypeError\u001b[0m: SyncServerHandler.__init__() got an unexpected keyword argument 'num_clients'"
     ]
    }
   ],
   "source": [
    "# client\n",
    "from fedlab.contrib.algorithm.basic_client import SGDSerialClientTrainer, SGDClientTrainer\n",
    "\n",
    "# local train configuration\n",
    "args.epochs = 5\n",
    "args.batch_size = 128\n",
    "args.lr = 0.1\n",
    "\n",
    "trainer = CompressSerialClientTrainer(model, args.total_client,\n",
    "                                 cuda=args.cuda)  # serial trainer\n",
    "# trainer = SGDClientTrainer(model, cuda=True) # single trainer\n",
    "\n",
    "trainer.setup_dataset(fed_mnist)\n",
    "trainer.setup_optim(args.epochs, args.batch_size, args.lr)\n",
    "trainer.setup_compressor(compressor)\n",
    "\n",
    "# server\n",
    "from fedlab.contrib.algorithm.basic_server import SyncServerHandler\n",
    "\n",
    "# global configuration\n",
    "args.com_round = 10\n",
    "args.sample_ratio = 0.1\n",
    "\n",
    "handler = CompressServerHandeler(model=model,\n",
    "                            global_round=args.com_round,\n",
    "                            num_clients=args.total_client,\n",
    "                            sample_ratio=args.sample_ratio,\n",
    "                            cuda=args.cuda)\n",
    "handler.setup_compressor(compressor, args.cmp_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 21.7808, test accuracy 0.2125\n",
      "loss 17.5083, test accuracy 0.4434\n",
      "loss 13.4432, test accuracy 0.5187\n",
      "loss 9.1679, test accuracy 0.6912\n",
      "loss 7.1598, test accuracy 0.7694\n",
      "loss 6.1386, test accuracy 0.8406\n",
      "loss 5.2171, test accuracy 0.8657\n",
      "loss 5.6939, test accuracy 0.8258\n",
      "loss 4.9492, test accuracy 0.8340\n",
      "loss 4.9229, test accuracy 0.8489\n"
     ]
    }
   ],
   "source": [
    "from fedlab.utils.functional import evaluate\n",
    "from fedlab.core.standalone import StandalonePipeline\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "class EvalPipeline(StandalonePipeline):\n",
    "    def __init__(self, handler, trainer, test_loader):\n",
    "        super().__init__(handler, trainer)\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "    def main(self):\n",
    "        while self.handler.if_stop is False:\n",
    "            # server side\n",
    "            sampled_clients = self.handler.sample_clients()\n",
    "            broadcast = self.handler.downlink_package\n",
    "\n",
    "            # client side\n",
    "            self.trainer.local_process(broadcast, sampled_clients)\n",
    "            uploads = self.trainer.uplink_package\n",
    "\n",
    "            # server side\n",
    "            for pack in uploads:\n",
    "                self.handler.load(pack)\n",
    "\n",
    "            loss, acc = evaluate(self.handler.model, nn.CrossEntropyLoss(),\n",
    "                                 self.test_loader)\n",
    "            print(\"loss {:.4f}, test accuracy {:.4f}\".format(loss, acc))\n",
    "\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(root=\"../datasets/mnist/\",\n",
    "                                       train=False,\n",
    "                                       transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(test_data, batch_size=1024)\n",
    "\n",
    "standalone_eval = EvalPipeline(handler=handler,\n",
    "                               trainer=trainer,\n",
    "                               test_loader=test_loader)\n",
    "standalone_eval.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('fedlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "019ae50596e3d4df627f3288be8543f4b17347150bdb9d2aa2e7c637014aee00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
